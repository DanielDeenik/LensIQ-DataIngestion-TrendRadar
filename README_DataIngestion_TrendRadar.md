# LensIQ Data Ingestion & TrendRadar

**Branch:** `LensIQ_DataIngestion_TrendRadar`  
**Focus:** Structured & Unstructured Data Ingestion + ML-Powered Trend Analysis  
**Status:** In Development

---

## ğŸ¯ Overview

This branch is a focused implementation of LensIQ that concentrates on two core capabilities:

1. **Multi-Source Data Ingestion** - Ingest structured and unstructured data from diverse sources
2. **TrendRadar** - ML/AI-powered dynamic trend detection and visualization

### Key Differentiators

- **Unstructured Data Support** - Reddit, LinkedIn, Discord
- **Structured Data Support** - SQL, MongoDB, CSV, Excel, JSON
- **Real-Time Processing** - Async data ingestion with Celery
- **ML-Powered Analysis** - Time series, anomaly detection, predictive forecasting
- **AI Insights** - OpenAI GPT for trend interpretation
- **Dynamic Visualization** - Interactive radar charts with real-time updates

---

## ğŸ“Š Data Sources

### Social Media (Unstructured)

| Source | Type | Data Points | Status |
|--------|------|-------------|--------|
| **Reddit** | Community discussions | Posts, comments, sentiment, engagement | âœ… Implemented |
| **LinkedIn** | Professional insights | Company updates, industry news, trends | ğŸš§ In Progress |
| **Discord** | Community chat | Messages, reactions, topics | âœ… Implemented |

### Databases (Structured)

| Source | Type | Use Case | Status |
|--------|------|----------|--------|
| **MongoDB** | Document DB | ESG data, trends, metrics | âœ… Implemented |
| **PostgreSQL** | Relational DB | Financial data, transactions | ğŸš§ In Progress |
| **MySQL** | Relational DB | Legacy data integration | ğŸš§ In Progress |

### Files (Structured)

| Format | Use Case | Status |
|--------|----------|--------|
| **CSV** | Bulk data import | âœ… Implemented |
| **Excel** | Spreadsheet data | âœ… Implemented |
| **JSON** | API responses, configs | âœ… Implemented |

---

## ğŸ¤– TrendRadar Features

### Machine Learning

- **Time Series Analysis** - ARIMA, Prophet for trend forecasting
- **Anomaly Detection** - Isolation Forest for unusual patterns
- **Clustering** - K-means for trend grouping
- **Classification** - Random Forest for trend categorization

### AI-Powered Insights

- **Natural Language Descriptions** - GPT-generated trend summaries
- **Impact Assessment** - AI-evaluated business impact
- **Competitive Analysis** - Cross-trend correlation
- **Risk/Opportunity Identification** - Automated alerts

### Dynamic Metrics

- **Client-Specific Prioritization** - Industry, size, geography
- **Real-Time Scoring** - Continuous trend strength assessment
- **Predictive Forecasting** - 30-day trend predictions
- **Confidence Intervals** - Statistical confidence levels

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Install all dependencies
pip install -r requirements-dataingestion.txt

# Or install core dependencies only
pip install -r requirements.txt
```

### 2. Configure Environment

Create `.env` file:

```bash
# Social Media APIs
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret
REDDIT_USER_AGENT=LensIQ/1.0

DISCORD_BOT_TOKEN=your_discord_bot_token

LINKEDIN_EMAIL=your_linkedin_email
LINKEDIN_PASSWORD=your_linkedin_password

# Databases
MONGODB_URI=mongodb://localhost:27017/lensiq
POSTGRES_URI=postgresql://user:pass@localhost:5432/lensiq
REDIS_URL=redis://localhost:6379/0

# AI/ML
OPENAI_API_KEY=your_openai_api_key

# Optional: Premium Data
REFINITIV_API_KEY=your_refinitiv_key
BLOOMBERG_API_KEY=your_bloomberg_key
```

### 3. Start Services

```bash
# Start MongoDB
mongod --dbpath /path/to/data

# Start Redis (for Celery)
redis-server

# Start Celery worker (for async tasks)
celery -A src.data_management.celery_app worker --loglevel=info

# Start Flask application
python app.py
```

### 4. Access TrendRadar

```bash
# Open in browser
open http://localhost:5000/trends
```

---

## ğŸ“ Project Structure

```
LensIQ_DataIngestion_TrendRadar/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_management/
â”‚   â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”‚   â”œâ”€â”€ reddit_connector.py          âœ… NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ discord_connector.py         âœ… NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ linkedin_connector.py        ğŸš§ TODO
â”‚   â”‚   â”‚   â”œâ”€â”€ sql_connector.py             ğŸš§ TODO
â”‚   â”‚   â”‚   â””â”€â”€ mongodb_connector.py         âœ… Enhanced
â”‚   â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”‚   â”œâ”€â”€ structured_pipeline.py       ğŸš§ TODO
â”‚   â”‚   â”‚   â”œâ”€â”€ unstructured_pipeline.py     ğŸš§ TODO
â”‚   â”‚   â”‚   â””â”€â”€ petastorm_pipeline.py        âœ… Existing
â”‚   â”‚   â””â”€â”€ rag_data_manager.py              âœ… Existing
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ trend_detection/
â”‚   â”‚   â”‚   â”œâ”€â”€ ml_trend_detector.py         ğŸš§ TODO
â”‚   â”‚   â”‚   â”œâ”€â”€ time_series_analyzer.py      ğŸš§ TODO
â”‚   â”‚   â”‚   â””â”€â”€ anomaly_detector.py          ğŸš§ TODO
â”‚   â”‚   â””â”€â”€ advanced_scoring.py              âœ… Existing
â”‚   â”‚
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ routes/
â”‚       â”‚   â””â”€â”€ trendradar.py                âœ… Enhanced
â”‚       â””â”€â”€ templates/
â”‚           â””â”€â”€ fin_radar/
â”‚               â””â”€â”€ fin_trendradar.html      âœ… Enhanced
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ DataIngestion_TrendRadar_Branch.md   âœ… Documentation
â”‚
â”œâ”€â”€ requirements-dataingestion.txt           âœ… Dependencies
â””â”€â”€ README_DataIngestion_TrendRadar.md       âœ… This file
```

---

## ğŸ”§ Usage Examples

### Ingest Reddit Data

```python
from src.data_management.connectors.reddit_connector import get_reddit_connector

# Initialize connector
reddit = get_reddit_connector()

# Get posts from subreddit
posts = reddit.get_subreddit_posts(
    subreddit_name='sustainability',
    limit=100,
    time_filter='week',
    sort_by='hot'
)

# Search for specific topics
esg_posts = reddit.search_subreddit(
    subreddit_name='investing',
    query='ESG',
    limit=50
)
```

### Ingest Discord Data

```python
from src.data_management.connectors.discord_connector import collect_discord_data

# Collect messages from channels
messages = await collect_discord_data(
    channel_ids=[123456789, 987654321],
    limit=100
)

# Process messages
for msg in messages:
    print(f"{msg.author}: {msg.content}")
```

### Run TrendRadar Analysis

```python
from src.frontend.routes.trendradar import TrendRadarRoute

# Initialize TrendRadar
radar = TrendRadarRoute()

# Get ML-powered trends
trends = radar._get_ml_powered_trends()

# Get trend predictions
predictions = radar._get_trend_predictions()
```

---

## ğŸ“ˆ Development Roadmap

### âœ… Phase 1: Foundation (Completed)
- [x] Create branch
- [x] Document architecture
- [x] Implement Reddit connector
- [x] Implement Discord connector
- [x] Create requirements file

### ğŸš§ Phase 2: Data Connectors (In Progress)
- [ ] Implement LinkedIn connector
- [ ] Implement SQL connector
- [ ] Enhance MongoDB connector
- [ ] Add data quality validation
- [ ] Create unified ingestion API

### ğŸ“… Phase 3: Data Pipelines (Planned)
- [ ] Build structured data pipeline
- [ ] Build unstructured data pipeline (NLP)
- [ ] Integrate sentiment analysis
- [ ] Add async processing with Celery
- [ ] Implement data caching

### ğŸ“… Phase 4: ML Trend Detection (Planned)
- [ ] Implement time series analysis (ARIMA, Prophet)
- [ ] Build anomaly detection (Isolation Forest)
- [ ] Create trend scoring algorithm
- [ ] Add predictive forecasting
- [ ] Implement trend clustering

### ğŸ“… Phase 5: AI Analysis (Planned)
- [ ] Integrate OpenAI GPT for insights
- [ ] Build metric prioritization engine
- [ ] Create client-specific customization
- [ ] Add trend correlation analysis
- [ ] Implement automated alerts

### ğŸ“… Phase 6: Enhanced Visualization (Planned)
- [ ] Upgrade radar chart with real-time data
- [ ] Add interactive drill-down
- [ ] Build metric dashboard
- [ ] Implement export functionality
- [ ] Add mobile responsiveness

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/test_reddit_connector.py

# Run with coverage
pytest --cov=src --cov-report=html
```

---

## ğŸ“š Documentation

- **Branch Overview:** `docs/DataIngestion_TrendRadar_Branch.md`
- **API Documentation:** Coming soon
- **User Guide:** Coming soon

---

## ğŸ¤ Contributing

This is a focused development branch. Key areas for contribution:

1. **Data Connectors** - Add new social media or database connectors
2. **ML Models** - Improve trend detection algorithms
3. **AI Insights** - Enhance GPT prompts and analysis
4. **Visualization** - Improve TrendRadar UI/UX
5. **Testing** - Add comprehensive test coverage

---

## ğŸ“ Notes

### Design Decisions

1. **Async-First** - All data ingestion uses async/await for performance
2. **Mock Fallbacks** - Graceful degradation when APIs unavailable
3. **Modular Architecture** - Easy to add new data sources
4. **ML Pipeline** - Petastorm for large-scale ML (optional)
5. **Client-Focused** - Dynamic metric prioritization per client

### Known Limitations

- LinkedIn connector requires unofficial API (rate limits apply)
- Discord requires bot token (must be added to servers)
- Reddit API has rate limits (60 requests/minute)
- ML models require training data (using mock data initially)

---

## ğŸ”— Links

- **Main Repository:** https://github.com/DanielDeenik/TrendSense
- **Project Board:** https://github.com/users/DanielDeenik/projects/4
- **Issues:** https://github.com/DanielDeenik/TrendSense/issues

---

**Last Updated:** December 1, 2025  
**Branch Status:** Active Development  
**Next Milestone:** Complete Phase 2 (Data Connectors)

